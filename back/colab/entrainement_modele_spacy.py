# -*- coding: utf-8 -*-
"""entrainement_modele_spacy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aCJfqzlMwdKOsjHvbwPvjsG0jXErX1iW

## **1. Charger et Préparer le Dataset**
"""

import pandas as pd

# Charger le fichier CSV
df = pd.read_csv('/content/entrainement_chatbot.csv')
# Supprimer les lignes où 'Question' est manquant
df = df.dropna(subset=['Question'])
# Afficher un aperçu des données
print(df.head())

print("null : ",df.isna().sum())
df.info()

"""## **2. Prétraitement des Données**"""

# Création d'une liste pour chaque question avec son tag (intention)
data = [(row['Question'], row['Tag']) for _, row in df.iterrows()]
# tags = df['Tag'].apply(str).unique()
# Récupérer les tags uniques
tags = df['Tag'].unique()
tags = df['Tag'].apply(str).unique()
print(data[:5])  # Vérifier les premières données
print(tags)  # Vérifier les tags uniques

"""## **3. Entraînement du Modèle SpaCy**

Charger le modèle et Ajouter le Pipeline de Classification :
"""

# import spacy

# spacy.cli.download("fr_core_news_md")

import spacy
from spacy.training import Example

# Charger un modèle vierge en français
nlp = spacy.blank("fr")

# Ajouter un pipeline de classification textuelle (intentions)
textcat = nlp.add_pipe("textcat")

# Ajouter les étiquettes (tags) pour les intentions
for tag in tags:
    textcat.add_label(tag)

# Préparer les données d'entraînement pour spaCy
TRAIN_DATA = []
for question, tag in data:
    # Créer les annotations pour chaque tag
    cats = {t: 1 if t == tag else 0 for t in tags}

    # Ajouter la question et ses annotations dans les données d'entraînement
    TRAIN_DATA.append((question, {"cats": cats}))

# Afficher quelques exemples des données préparées
print(TRAIN_DATA[:3])

"""Entraîner le Modèle avec les Données :"""

# # Entraînement du modèle avec spaCy
# Initialisation de l'optimiseur pour le modèle
optimizer = nlp.begin_training()

# Nombre d'itérations (epochs) pour l'entraînement
n_iter = 10

# Boucle sur chaque itération d'entraînement
for itn in range(n_iter):
    # Dictionnaire pour stocker les pertes (losses) pendant cette itération
    losses = {}

    # Boucle sur les données d'entraînement
    for text, annotations in TRAIN_DATA:
        # Vérification si 'text' est une chaîne de caractères et non 'nan'
        if isinstance(text, str) and text != 'nan':
            # Création d'un document spaCy à partir du texte
            doc = nlp.make_doc(text)
            # Création d'un exemple à partir du document et des annotations
            example = Example.from_dict(doc, annotations)
            # Mise à jour du modèle avec l'exemple, en appliquant un taux de dropout de 0.2
            nlp.update([example], drop=0.2, losses=losses)

    # Affichage des pertes pour l'itération actuelle
    print(f"Iteration {itn + 1} - Losses: {losses}")

# Sauvegarder le modèle entraîné
nlp.to_disk("/content/modele_veenge_maan_chatbot_juridique")

# Télécharger le modèle sur ton local depuis Colab
from google.colab import files
import shutil

shutil.make_archive("modele_veenge_maan_chatbot_juridique", 'zip', "/content/modele_veenge_maan_chatbot_juridique")
files.download("modele_veenge_maan_chatbot_juridique.zip")

"""## **4. Évaluation du Modèle**"""

test_df = pd.read_csv("/content/tester_modele_spacy.csv")
test_df = test_df[["Tag", "Question", "Réponse"]]
test_df.info()

from sklearn.metrics import classification_report

# Fonction pour évaluer le modèle SpaCy
def evaluate_model(nlp, valid_data):
    predictions = []
    true_labels = []

    for text, annotations in valid_data:
        # Prédire le tag de la question
        doc = nlp(text)
        predicted_label = max(doc.cats, key=doc.cats.get)

        # Extraire le tag réel depuis les annotations
        true_label = max(annotations["cats"], key=annotations["cats"].get)

        predictions.append(predicted_label)
        true_labels.append(true_label)

    # Afficher le rapport de classification
    print(classification_report(true_labels, predictions))

# Exécuter la fonction d'évaluation l'ensemble de validation
valid_data = TRAIN_DATA[:]

# Exécuter la fonction d'évaluation sur l'ensemble de test
evaluate_model(nlp, valid_data)

#  un ensemble de test
test_df = pd.read_csv("/content/tester_modele_spacy.csv")
test_df = test_df[["Tag", "Question", "Réponse"]]
test_df.info()

#  un ensemble de test

# Préparer les données de test
y_true = []
y_pred = []

for _, row in test_df.iterrows():
    text = row['Question']
    true_tag = row['Tag']
    y_true.append(true_tag)

    # Prédiction du modèle
    doc = nlp(text)
    predicted_tag = doc.cats
    # Choisir le tag avec la probabilité maximale
    predicted_tag = max(predicted_tag, key=predicted_tag.get)
    y_pred.append(predicted_tag)

# Calcul des métriques
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

precision = precision_score(y_true, y_pred, average='weighted')
recall = recall_score(y_true, y_pred, average='weighted')
f1 = f1_score(y_true, y_pred, average='weighted')
accuracy = accuracy_score(y_true, y_pred)
unique_labels = set(y_true)
predicted_labels = set(y_pred)

# Étiquettes qui n'ont pas été prédites
missing_labels = unique_labels - predicted_labels
print(f"Étiquettes non prédites : {missing_labels}")

print(f"Précision: {precision:.2f}")
print(f"Rappel: {recall:.2f}")
print(f"F1-score: {f1:.2f}")
print(f"Exactitude: {accuracy:.2f}")

"""## **5. Sauvegarde et Chargement du Modèle**"""

# Sauvegarder le modèle entraîné
nlp.to_disk("/content/modele_veenge_maan_chatbot_juridique")

# Télécharger le modèle sur ton local depuis Colab
from google.colab import files
import shutil

shutil.make_archive("modele_veenge_maan_chatbot_juridique", 'zip', "/content/modele_veenge_maan_chatbot_juridique")
files.download("modele_veenge_maan_chatbot_juridique.zip")

